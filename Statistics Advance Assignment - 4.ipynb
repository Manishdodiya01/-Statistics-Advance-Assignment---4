{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6066cb2-052a-4ae6-85be-e8c0e56ac7c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Q1: What is the difference between a t-test and a z-test? Provide an example scenario where you would use each type of test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f24d54f-a757-45f5-9185-b0790614afcb",
   "metadata": {},
   "source": [
    "The t-test and z-test are both statistical hypothesis tests used to compare means of two groups or to determine if a sample mean differs significantly from a population mean. The main difference between the two tests lies in the circumstances under which they are applicable.\n",
    "\n",
    "1. t-test:\n",
    "The t-test is used when the sample size is relatively small (typically, when the sample size is less than 30) and the population standard deviation is unknown. It is also appropriate when the data is approximately normally distributed. There are two main types of t-tests:\n",
    "\n",
    "- One-sample t-test: Used to determine if the mean of a sample significantly differs from a known population mean.\n",
    "- Independent samples t-test: Used to compare the means of two independent groups (samples) to see if they are significantly different from each other.\n",
    "\n",
    "Example scenario for t-test: Let's say you want to compare the average scores of two groups of students, where each group contains fewer than 30 students. You don't know the population standard deviation, but you can assume that the data is approximately normally distributed. In this case, you would use an independent samples t-test to assess whether there is a significant difference between the mean scores of the two groups.\n",
    "\n",
    "2. z-test:\n",
    "The z-test is used when the sample size is large (typically, when the sample size is greater than 30) and the population standard deviation is known. It is also suitable when the data is normally distributed. The z-test is less commonly used in practice compared to the t-test because the population standard deviation is often unknown in real-world scenarios.\n",
    "\n",
    "Example scenario for z-test: Imagine you have a large dataset of exam scores from a university, and you know the population standard deviation of scores for that particular exam. You want to determine if the average score of a specific class significantly differs from the overall average score of the university. In this situation, you would use a z-test to compare the class's mean score with the known population mean.\n",
    "\n",
    "In summary, use the t-test when the sample size is small and/or the population standard deviation is unknown. Use the z-test when the sample size is large and the population standard deviation is known. If the sample size is large, and the population standard deviation is unknown, the t-test is still a suitable choice, but it approaches the z-test as the sample size increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514299fd-603d-4c54-9111-63f4228ae2a8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Q2: Differentiate between one-tailed and two-tailed tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c67527c-593b-4fe2-a3e6-bb596b25e1d6",
   "metadata": {},
   "source": [
    "One-tailed and two-tailed tests are two types of hypothesis tests used in statistics to determine whether there is a significant difference or relationship between groups or variables. The key difference between these tests lies in the directionality of the hypothesis being tested.\n",
    "\n",
    "1. One-tailed test:\n",
    "In a one-tailed test, the null hypothesis specifies a particular direction for the effect or relationship, while the alternative hypothesis (research hypothesis) specifies the opposite direction. The one-tailed test is used when researchers have a specific expectation or hypothesis about the direction of the effect.\n",
    "\n",
    "For example, let's consider testing the effect of a new drug on participants' reaction times. The hypotheses would be formulated as follows:\n",
    "\n",
    "Null hypothesis (H0): The new drug has no effect on reaction times.\n",
    "Alternative hypothesis (H1): The new drug decreases reaction times.\n",
    "\n",
    "In this case, you would conduct a one-tailed test to see if there is enough evidence to reject the null hypothesis in favor of the alternative hypothesis, specifically looking for a decrease in reaction times due to the new drug.\n",
    "\n",
    "The critical region for a one-tailed test is located entirely in one tail of the distribution, making it easier to achieve statistical significance if the data supports the expected direction.\n",
    "\n",
    "2. Two-tailed test:\n",
    "In a two-tailed test, the null hypothesis simply states that there is no significant difference or relationship, without specifying a particular direction. The alternative hypothesis, on the other hand, asserts that there is a significant difference or relationship, but it does not specify the direction.\n",
    "\n",
    "Continuing with the same example of testing the effect of a new drug on reaction times, the hypotheses for a two-tailed test would be formulated as follows:\n",
    "\n",
    "Null hypothesis (H0): The new drug has no effect on reaction times.\n",
    "Alternative hypothesis (H1): The new drug has a significant effect on reaction times (either increasing or decreasing).\n",
    "\n",
    "In a two-tailed test, you are interested in whether there is a significant change in either direction—either an increase or decrease in reaction times.\n",
    "\n",
    "The critical region for a two-tailed test is split between both tails of the distribution, making it less likely to achieve statistical significance compared to a one-tailed test, as the evidence must support a significant effect regardless of the direction.\n",
    "\n",
    "In summary, a one-tailed test is used when researchers have a specific directional hypothesis, and they want to determine if the data supports that specific direction. A two-tailed test, on the other hand, is used when researchers are interested in any significant effect, regardless of the direction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91699bf6-f08d-4e3d-a923-f2b2c3c514c2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Q3: Explain the concept of Type 1 and Type 2 errors in hypothesis testing. Provide an example scenario for each type of error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29075365-e931-4a28-8311-7960941ad802",
   "metadata": {},
   "source": [
    "In hypothesis testing, Type 1 and Type 2 errors are two types of mistakes that can occur when making decisions about the null hypothesis (H0) and alternative hypothesis (H1).\n",
    "\n",
    "1. Type 1 error (False Positive or α-error):\n",
    "A Type 1 error occurs when we reject the null hypothesis (H0) when it is actually true. In other words, we conclude that there is a significant effect or relationship when, in reality, there is no effect or relationship in the population. The probability of committing a Type 1 error is denoted by the symbol α (alpha) and is also known as the significance level.\n",
    "\n",
    "Example scenario for Type 1 error:\n",
    "Imagine a medical test designed to detect a specific disease. The null hypothesis (H0) in this case would be that the person being tested does not have the disease. The alternative hypothesis (H1) would be that the person does have the disease. If the test is overly sensitive or not well-calibrated, it may produce false positives, indicating that a person has the disease when, in fact, they do not.\n",
    "\n",
    "2. Type 2 error (False Negative or β-error):\n",
    "A Type 2 error occurs when we fail to reject the null hypothesis (H0) when it is actually false. In other words, we conclude that there is no significant effect or relationship when, in reality, there is an effect or relationship in the population. The probability of committing a Type 2 error is denoted by the symbol β (beta).\n",
    "\n",
    "Example scenario for Type 2 error:\n",
    "Consider a clinical trial for a new drug intended to lower blood pressure. The null hypothesis (H0) would be that the drug has no effect on blood pressure, while the alternative hypothesis (H1) would be that the drug does lower blood pressure. If the trial lacks statistical power or the sample size is too small, it may fail to detect the drug's actual effect, leading to a Type 2 error. In this case, the trial would conclude that the drug is ineffective when it actually could be effective.\n",
    "\n",
    "It's important to note that the probabilities of Type 1 and Type 2 errors are typically related, meaning that decreasing the probability of one type of error often increases the probability of the other. Researchers must choose an appropriate significance level (α) when designing their experiments to control the risk of Type 1 error. Additionally, they should consider factors like sample size and effect size to mitigate the risk of Type 2 error and ensure the statistical power of their study is sufficient to detect meaningful effects if they exist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a261ca-56b8-4a44-b800-74189b769d05",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Q4: Explain Bayes's theorem with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb0ed1d-901e-4c68-a09c-c0b6accb1fb5",
   "metadata": {},
   "source": [
    "Bayes's theorem, named after the Reverend Thomas Bayes, is a fundamental concept in probability theory and statistics. It provides a way to update the probability of a hypothesis based on new evidence. The theorem mathematically describes the relationship between conditional probabilities, allowing us to make more informed decisions in the presence of uncertain or incomplete information.\n",
    "\n",
    "The formula for Bayes's theorem is as follows:\n",
    "\n",
    "\\[ P(H|E) = \\frac{P(E|H) \\cdot P(H)}{P(E)} \\]\n",
    "\n",
    "Where:\n",
    "- \\( P(H|E) \\) is the posterior probability of hypothesis H given evidence E.\n",
    "- \\( P(E|H) \\) is the likelihood of evidence E given hypothesis H.\n",
    "- \\( P(H) \\) is the prior probability of hypothesis H (the probability of H before considering any evidence).\n",
    "- \\( P(E) \\) is the probability of evidence E (the normalizing constant).\n",
    "\n",
    "Now, let's illustrate Bayes's theorem with a classic example known as the \"diagnostic test\" scenario:\n",
    "\n",
    "Example scenario:\n",
    "Suppose you are a doctor, and you have a patient who is experiencing flu-like symptoms. You want to determine the probability that the patient has the flu (H) based on the results of a diagnostic test (E). You know the following probabilities:\n",
    "\n",
    "1. Prior probability: \\( P(\\text{Flu}) = 0.05 \\) (The probability that a randomly selected person has the flu, before any test results).\n",
    "2. Sensitivity: \\( P(\\text{Positive Test Result} | \\text{Flu}) = 0.9 \\) (The probability that the test correctly identifies a person with the flu as positive).\n",
    "3. Specificity: \\( P(\\text{Negative Test Result} | \\text{No Flu}) = 0.95 \\) (The probability that the test correctly identifies a person without the flu as negative).\n",
    "\n",
    "Now, you want to find the probability that the patient has the flu given a positive test result.\n",
    "\n",
    "Using Bayes's theorem:\n",
    "Let H be the event \"the patient has the flu,\" and E be the event \"the test result is positive.\"\n",
    "\n",
    "\\[ P(\\text{Flu}|\\text{Positive Test}) = \\frac{P(\\text{Positive Test}|\\text{Flu}) \\cdot P(\\text{Flu})}{P(\\text{Positive Test})} \\]\n",
    "\n",
    "To compute the denominator, we need to consider all possibilities that could lead to a positive test result:\n",
    "\n",
    "\\[ P(\\text{Positive Test}) = P(\\text{Positive Test}|\\text{Flu}) \\cdot P(\\text{Flu}) + P(\\text{Positive Test}|\\text{No Flu}) \\cdot P(\\text{No Flu}) \\]\n",
    "\n",
    "Since \\( P(\\text{No Flu}) = 1 - P(\\text{Flu}) \\) (the probability of not having the flu), we can calculate the denominator and then find the posterior probability of having the flu given a positive test result.\n",
    "\n",
    "By substituting the known values, you can now calculate \\( P(\\text{Flu}|\\text{Positive Test}) \\). The result will give you the probability that the patient actually has the flu, given the positive test result. This updated probability takes into account both the prior probability of having the flu and the test's accuracy in identifying true positive cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd39435-922f-478c-aa24-58dd34ac488c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Q5: What is a confidence interval? How to calculate the confidence interval, explain with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2e7762-6745-4822-93b1-b4845533acc5",
   "metadata": {},
   "source": [
    "A confidence interval is a range of values within which we are reasonably confident that the true population parameter (e.g., mean, proportion) lies. It provides a measure of the uncertainty associated with estimating a population parameter from a sample.\n",
    "\n",
    "When conducting statistical analysis, we often have a sample from a population, and we want to estimate an unknown population parameter. A point estimate (e.g., sample mean, sample proportion) gives us a single value as an estimate, but it doesn't tell us anything about the uncertainty associated with that estimate. A confidence interval, on the other hand, gives us a range of values that is likely to contain the true population parameter with a specified level of confidence.\n",
    "\n",
    "The confidence interval is often expressed as:\n",
    "\n",
    "\\[ \\text{Point Estimate} \\pm \\text{Margin of Error} \\]\n",
    "\n",
    "The margin of error is calculated based on the variability in the data and the desired level of confidence.\n",
    "\n",
    "Example of calculating a confidence interval for the population mean:\n",
    "\n",
    "Suppose you want to estimate the average height of students in a university. You take a random sample of 100 students and measure their heights. Let's assume the sample mean height is 170 cm, and the sample standard deviation is 5 cm.\n",
    "\n",
    "1. Choose the level of confidence: Let's say you want a 95% confidence interval. This means you want to be 95% confident that the true average height of all students in the university lies within the interval.\n",
    "\n",
    "2. Find the critical value: Since you have a large enough sample (n > 30) and you know the sample standard deviation, you can use the Z-table for a 95% confidence level. The critical value for a 95% confidence interval is approximately 1.96.\n",
    "\n",
    "3. Calculate the margin of error: The margin of error (ME) is given by:\n",
    "\n",
    "\\[ ME = \\text{Critical Value} \\times \\frac{\\text{Sample Standard Deviation}}{\\sqrt{\\text{Sample Size}}} \\]\n",
    "\n",
    "\\[ ME = 1.96 \\times \\frac{5}{\\sqrt{100}} = 1.96 \\times 0.5 = 0.98 \\]\n",
    "\n",
    "4. Calculate the confidence interval: Now, you can construct the confidence interval using the formula:\n",
    "\n",
    "\\[ \\text{Confidence Interval} = \\text{Sample Mean} \\pm \\text{Margin of Error} \\]\n",
    "\n",
    "\\[ \\text{Confidence Interval} = 170 \\pm 0.98 \\]\n",
    "\n",
    "The 95% confidence interval for the average height of all students in the university is (169.02, 170.98) cm. This means that you are 95% confident that the true average height lies between these two values.\n",
    "\n",
    "Remember that increasing the level of confidence will widen the confidence interval, making it more likely to capture the true population parameter, but at the cost of increased uncertainty. Confidence intervals are an essential tool in statistics to help us draw meaningful conclusions and make inferences about population parameters based on sample data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f186cb9-31bc-4991-9ab1-432233aa42a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Q6. Use Bayes' Theorem to calculate the probability of an event occurring given prior knowledge of the event's probability and new evidence. Provide a sample problem and solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d8ce8d-4161-429c-83bb-78f734560437",
   "metadata": {},
   "source": [
    "You have two bags, Bag A and Bag B, containing some marbles.\n",
    "Bag A has 2 red marbles and 3 blue marbles.\n",
    "Bag B has 1 red marble and 4 blue marbles.\n",
    "\n",
    "You randomly pick one bag and then randomly draw one marble from the chosen bag. The marble turns out to be red. What is the probability that you picked Bag A?\n",
    "\n",
    "A: Picking Bag A.\n",
    "B: Drawing a red marble.\n",
    "\n",
    "P(A) == 0.5\n",
    "P(B|A) = 2/5\n",
    "\n",
    "#P(B) = P(B|A) * P(A) + P(B|¬A) * P(¬A)\n",
    "P(B) = (0.4 * 0.5) + (0.2 * 0.5)\n",
    "P(B) = 0.2 + 0.1\n",
    "P(B) = 0.3\n",
    "\n",
    "P(A|B) = (P(A) * P(B/A) / P(B))\n",
    "P(A|B) = (0.5 * 0.4) / 0.3\n",
    "P(A|B) = 0.2 / 0.3\n",
    "P(A|B) = 0.6667"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0b1a8f-ed83-46bb-8f14-8fb0ff46349a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Q7. Calculate the 95% confidence interval for a sample of data with a mean of 50 and a standard deviation of 5. Interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "862d4f54-3aea-4322-aaa7-4181a9f69778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence interval:  (40.200180077299734, 59.799819922700266)\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "sample_mean = 50\n",
    "sample_std = 5\n",
    "ci = stats.norm.interval(confidence= 0.95 , loc=50 , scale = 5)\n",
    "print(\"95% Confidence interval: \",ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3f08e1-342f-400e-80d9-498f2ffa057f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Q8. What is the margin of error in a confidence interval? How does sample size affect the margin of error? Provide an example of a scenario where a larger sample size would result in a smaller margin of error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdaccb1-66c8-4e2b-802b-468c443e9c05",
   "metadata": {},
   "source": [
    "The margin of error in a confidence interval is a measure of the uncertainty or precision of the estimate of a population parameter (e.g., mean, proportion) based on a sample. It quantifies the range within which the true population parameter is likely to lie. A smaller margin of error indicates a more precise estimate, while a larger margin of error indicates a less precise estimate.\n",
    "\n",
    "In general, the margin of error is affected by three main factors:\n",
    "1. Confidence level: The higher the confidence level (e.g., 95%, 99%), the larger the margin of error, as it requires a wider interval to capture a higher proportion of potential sample estimates.\n",
    "2. Standard deviation or variability of the population: A larger population standard deviation results in a larger margin of error since the data points are more spread out, leading to greater uncertainty in the estimate.\n",
    "3. Sample size: A larger sample size leads to a smaller margin of error. As the sample size increases, the variability between individual data points decreases, leading to a more precise estimate.\n",
    "\n",
    "Example Scenario:\n",
    "\n",
    "Suppose you want to estimate the average height of students in a university. You can take two different sample sizes: one with 30 students and another with 300 students.\n",
    "\n",
    "For the sample with 30 students:\n",
    "- Assume the sample mean height is 170 cm.\n",
    "- Assume the standard deviation of the height in the population is 8 cm.\n",
    "- Assume a 95% confidence level.\n",
    "\n",
    "Using the formula for the margin of error:\n",
    "\n",
    "Margin of error = (Z * (σ / √n))\n",
    "\n",
    "where:\n",
    "- Z is the critical value from the standard normal distribution corresponding to the desired confidence level (for 95% confidence, Z ≈ 1.96).\n",
    "- σ is the population standard deviation.\n",
    "- n is the sample size.\n",
    "\n",
    "For the sample with 30 students:\n",
    "Margin of error = (1.96 * (8 / √30)) ≈ 2.78 cm\n",
    "\n",
    "For the sample with 300 students:\n",
    "Margin of error = (1.96 * (8 / √300)) ≈ 0.73 cm\n",
    "\n",
    "As you can see, the larger sample size (300 students) resulted in a smaller margin of error (0.73 cm) compared to the smaller sample size (30 students) with a margin of error of 2.78 cm. This demonstrates that a larger sample size provides a more precise estimate with a smaller range of uncertainty around the estimated population parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ce13bc-ef2a-4e6e-ab53-4f5bd87f4cc6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Q9. Calculate the z-score for a data point with a value of 75, a population mean of 70, and a population standard deviation of 5. Interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb868885-eed2-4dc7-a0f1-a8ae49464e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "Value = 75\n",
    "Population_mean = 70\n",
    "Population_std = 5\n",
    "\n",
    "Z_Score = (Value - Population_mean) / Population_std\n",
    "print(f\"Z-Score: {Z_Score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72992987-e20c-45cf-bd68-2cafef90d85f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Q10. In a study of the effectiveness of a new weight loss drug, a sample of 50 participants lost an average of 6 pounds with a standard deviation of 2.5 pounds. Conduct a hypothesis test to determine if the drug is significantly effective at a 95% confidence level using a t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb7b6e82-2f59-4110-b814-1cc95b5ece32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistics: 16.970562748477143\n",
      "Decision_rule: 2.009575234489209\n",
      "Reject the null hypothesis\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "n = 50\n",
    "sample_mean = 6\n",
    "sample_std = 2.5\n",
    "alpha = 1 - 0.95\n",
    "df = n - 1\n",
    "\n",
    "Decision_rule = stats.t.ppf(1 - alpha / 2 , df)\n",
    "t_statistics = (sample_mean) / (sample_std / np.sqrt(n))\n",
    "\n",
    "print(f\"t-statistics: {t_statistics}\")\n",
    "print(f\"Decision_rule: {Decision_rule}\")\n",
    "if t_statistics > Decision_rule:\n",
    "    print(\"Reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b33f20d-da65-4d43-bb44-e53699f4f377",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Q11. In a survey of 500 people, 65% reported being satisfied with their current job. Calculate the 95% confidence interval for the true proportion of people who are satisfied with their job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ae79041-4635-4c00-98a7-3c433710b172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence_interval: (0.6081925393809212, 0.6918074606190788)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "sample_size = 500\n",
    "Confidence_level = 0.95\n",
    "Sample_proportion = 0.65\n",
    "alpha = 1 - Confidence_level\n",
    "\n",
    "margin_error = stats.norm.ppf(1 - (alpha) / 2)  *  np.sqrt(Sample_proportion * (1 - Sample_proportion) / sample_size)\n",
    "confidence_interval = (Sample_proportion - margin_error , Sample_proportion + margin_error)\n",
    "print(f\"Confidence_interval: {confidence_interval}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03eb9d88-6573-4fbc-a75f-7ae534dee7e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Q12. A researcher is testing the effectiveness of two different teaching methods on student performance. Sample A has a mean score of 85 with a standard deviation of 6, while sample B has a mean score of 82 with a standard deviation of 5. Conduct a hypothesis test to determine if the two teaching methods have a significant difference in student performance using a t-test with a significance level of 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5f0ea9a-beb1-40a1-8b5f-2d7407391ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision_rule:  2.6264054563851857\n",
      "t-statistics:  1.928473039599675\n",
      "Fail to reject the null hypothesis\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "sample_a_mean = 85\n",
    "sample_b_mean = 82\n",
    "sample_a_std = 6\n",
    "sample_b_std = 5\n",
    "n1 = 50\n",
    "n2 = 50\n",
    "alpha = 0.01\n",
    "df = n1+n2 - 1\n",
    "\n",
    "decision_rule = stats.t.ppf(1 - alpha / 2 , df)\n",
    "t_statistics = (sample_a_mean - sample_b_mean) / (sample_a_std / np.sqrt(n1) + (sample_b_std / np.sqrt(n2)))\n",
    "\n",
    "print(\"decision_rule: \",decision_rule)\n",
    "print(\"t-statistics: \",t_statistics)\n",
    "if t_statistics > decision_rule:\n",
    "    print(\"Reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd1f3b0-663b-4f26-995b-844cd30c994a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Q13. A population has a mean of 60 and a standard deviation of 8. A sample of 50 observations has a mean of 65. Calculate the 90% confidence interval for the true population mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea852c96-fae7-4395-b964-280fa9ed38d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 % Confidence Interval:  (64.95819253938092, 65.04180746061908)\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "n = 50\n",
    "mean = 60\n",
    "std = 8\n",
    "sample_mean = 65\n",
    "alpha = 1 - 0.90\n",
    "\n",
    "z_score = stats.norm.ppf(1 - alpha / 2)\n",
    "margin_of_error = z_score * (std / np.sqrt(n))\n",
    "c_interval = (sample_mean - margin_error , sample_mean + margin_error)\n",
    "print(\"90 % Confidence Interval: \",c_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5fb2e4-d087-45a8-91fe-60c61ed45f55",
   "metadata": {},
   "source": [
    "# Q14. In a study of the effects of caffeine on reaction time, a sample of 30 participants had an average reaction time of 0.25 seconds with a standard deviation of 0.05 seconds. Conduct a hypothesis test to determine if the caffeine has a significant effect on reaction time at a 90% confidence level using a t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84e592dd-b82b-4767-a3ab-644ff6474b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision_rule:  2.6264054563851857\n",
      "T-statistics:  27.386127875258307\n",
      "Reject the null hypothesis\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "n = 30\n",
    "mean = 0.25\n",
    "std = 0.05\n",
    "alpha = 1 - 0.90\n",
    "df = n - 1\n",
    "\n",
    "decision_rule_rule = stats.t.ppf(1 - alpha / 2 ,df)\n",
    "t_statistics = (mean) / (std / np.sqrt(n))\n",
    "\n",
    "print(\"decision_rule: \",decision_rule)\n",
    "print(\"T-statistics: \",t_statistics)\n",
    "\n",
    "if t_statistics > decision_rule:\n",
    "    print(\"Reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514249ec-3faf-4c48-8028-8a969ff94e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
